# -*- coding: utf-8 -*-
"""2nd round âœ… 4. MobileNet_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1geSQyz6MgL49V8mV8oY2neHECGtqtVVY

# Imports
"""

import os
import tensorflow as tf
import matplotlib.pyplot as plt

"""# Data Loading"""

from google.colab import drive
drive.mount('/content/drive')

# Specifying file paths for the data directories
TRAIN_DIR = '/content/drive/MyDrive/pepper_mate_models/disease_classification_models/dataset/train/'
VALIDATION_DIR = '/content/drive/MyDrive/pepper_mate_models/disease_classification_models/dataset/valid/'
TEST_DIR = '/content/drive/MyDrive/pepper_mate_models/disease_classification_models/dataset/test/'

# Specifying file paths for the each class in the training dataset
pollu_beetle_dir = os.path.join(TRAIN_DIR, 'pollu_beetle')
brown_spot_dir = os.path.join(TRAIN_DIR, 'brown_spot')
healthy_dir = os.path.join(TRAIN_DIR, 'healthy')
leaf_blight_dir = os.path.join(TRAIN_DIR, 'leaf_blight')
little_leaf_dir = os.path.join(TRAIN_DIR, 'little_leaf')
quick_wilt_dir = os.path.join(TRAIN_DIR, 'quick_wilt')
slow_wilt_dir = os.path.join(TRAIN_DIR, 'slow_wilt')
white_spot_dir = os.path.join(TRAIN_DIR, 'white_spot')
thrips_dir = os.path.join(TRAIN_DIR, 'thrips')

"""# Data visualization"""

# Loading first example of the each class
sample_pollu_beetle = tf.keras.preprocessing.image.load_img(os.path.join(pollu_beetle_dir, os.listdir(pollu_beetle_dir)[0]))
sample_brown_spot = tf.keras.preprocessing.image.load_img(os.path.join(brown_spot_dir, os.listdir(brown_spot_dir)[0]))
sample_healthy = tf.keras.preprocessing.image.load_img(os.path.join(healthy_dir, os.listdir(healthy_dir)[0]))
sample_leaf_blight = tf.keras.preprocessing.image.load_img(os.path.join(leaf_blight_dir, os.listdir(leaf_blight_dir)[0]))
sample_little_leaf_disease = tf.keras.preprocessing.image.load_img(os.path.join(little_leaf_dir, os.listdir(little_leaf_dir)[0]))
sample_quick_wilt = tf.keras.preprocessing.image.load_img(os.path.join(quick_wilt_dir, os.listdir(quick_wilt_dir)[0]))
sample_slow_wilt = tf.keras.preprocessing.image.load_img(os.path.join(slow_wilt_dir, os.listdir(slow_wilt_dir)[0]))
sample_white_spot = tf.keras.preprocessing.image.load_img(os.path.join(white_spot_dir, os.listdir(white_spot_dir)[0]))
sample_thrips = tf.keras.preprocessing.image.load_img(os.path.join(thrips_dir, os.listdir(thrips_dir)[0]))

# Create a figure and an array of subplots
fig, axes = plt.subplots(3, 3, figsize=(10, 10))

# Flatten the axes array for easier iteration
axes = axes.ravel()

# Define a list of sample images and their corresponding titles
sample_images = [
    sample_pollu_beetle, sample_brown_spot, sample_healthy,
    sample_leaf_blight, sample_little_leaf_disease, sample_quick_wilt,
    sample_slow_wilt, sample_white_spot, sample_thrips
]
titles = [
    'Pollu Beetle', 'Brown Spot', 'Healthy',
    'Leaf Blight', 'Little Leaf', 'Quick Wilt',
    'Slow Wilt', 'White Spot', 'Thrips'
]

# Iterate through the sample images and display them in the subplots
for i in range(9):  # Assuming you have 9 sample images
    axes[i].imshow(sample_images[i])
    axes[i].set_title(titles[i])
    axes[i].axis('off')

# Adjust the spacing between subplots and display the plot
plt.tight_layout()
plt.show()

# Converting an image into its numpy array representation
sample_array = tf.keras.preprocessing.image.img_to_array(sample_healthy)

print(f"Each image has shape: {sample_array.shape}")

"""# Creating training, validation and test sets"""

# Defining a function to create the training, validation and test sets
def train_val_test_datasets():
    """Creates training, validation and test datasets

    Returns:
        (tf.data.Dataset, tf.data.Dataset): training, validation and test datasets
    """

    # Create the training dataset
    # Here we have used image generators (it will do image labeling for us)
    training_dataset = tf.keras.utils.image_dataset_from_directory(
        directory=TRAIN_DIR,        # Use the training directory
        batch_size=32,              # Set batch size to 32
        image_size=(640, 640),      # Resize images to 500x500
        shuffle=True,               # Shuffle the dataset
        seed=7,                     # Set seed for reproducibility
        label_mode='categorical'    # Use categorical labels for multi-class classification
    )

    # Create the validation dataset
    validation_dataset = tf.keras.utils.image_dataset_from_directory(
        directory=VALIDATION_DIR,   # Use the validation directory
        batch_size=32,              # Set batch size to 32
        image_size=(640, 640),      # Resize images to 500x500
        shuffle=True,               # Shuffle the dataset
        seed=7,                     # Set seed for reproducibility
        label_mode='categorical'    # Use categorical labels for multi-class classification
    )

    # Create the test dataset
    test_dataset = tf.keras.utils.image_dataset_from_directory(
        directory=TEST_DIR,         # Use the test directory
        batch_size=32,              # Set batch size to 32
        image_size=(640, 640),      # Resize images to 500x500
        shuffle=True,               # Shuffle the dataset
        seed=7,                     # Set seed for reproducibility
        label_mode='categorical'    # Use categorical labels for multi-class classification
    )

    return training_dataset, validation_dataset, test_dataset

# Calling the dataset generation function
training_dataset, validation_dataset, test_dataset = train_val_test_datasets()

# Counting number of batches in each dataset
print(f'Number of training batches: {training_dataset.cardinality()}')
print(f'Number of validation batches: {validation_dataset.cardinality()}')
print(f'Number of test batches: {test_dataset.cardinality()}')

"""# Data pre processing for the Inception v3 Model"""

# # Define the preprocess function
# def preprocess(image, label):
#     image = tf.keras.applications.inception_v3.preprocess_input(image)
#     return image, label

# # Apply the preprocessing to the datasets
# train_dataset_scaled = training_dataset.map(preprocess)
# validation_dataset_scaled = validation_dataset.map(preprocess)
# test_dataset_scaled = test_dataset.map(preprocess)

"""# Loading the weights file"""

# local_weights_file = '/content/drive/My Drive/pepper_mate_models/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'

"""# Setup the pretrained model"""

input_shape = (640, 640, 3)

# Load the base model
mbnet_v2 = tf.keras.applications.MobileNetV2(
    weights="imagenet",
    include_top=False,
    input_shape=input_shape
)

# Unfreeze the top layers for fine-tuning (adjust the number of layers as needed)
for layer in mbnet_v2.layers[:-50]:  # Keeping lower layers frozen, adjust this number as needed
    layer.trainable = False
for layer in mbnet_v2.layers[-50:]:
    layer.trainable = True

mbnet_v2.summary()

"""# Add dense layers for your classifier"""

# Define the model structure
inputs = tf.keras.Input(shape=input_shape)
x = mbnet_v2(inputs, training=True)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dropout(0.2)(x)
outputs = tf.keras.layers.Dense(9, activation="softmax")(x)

# Combine the model
model = tf.keras.Model(inputs=inputs, outputs=outputs)

model.summary()

# Add the learning rate scheduler callback
lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_accuracy',  # Monitor validation accuracy
    factor=0.5,               # Reduce learning rate by half if no improvement
    patience=2,               # Wait for 2 epochs before reducing
    min_lr=1e-6,              # Set a lower bound for the learning rate
    verbose=1
)

# Compile with an initial learning rate
initial_learning_rate = 0.0001
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=initial_learning_rate),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)

# Early stopping callback (optional, for training stability)
early_stopping_cb = tf.keras.callbacks.EarlyStopping(
    monitor="val_loss",
    patience=5,
    restore_best_weights=True
)

"""# Check the model architecture"""

# Checking that the input and output shape of your model are correct
print(f'Input shape: {model.input_shape}')
print(f'Output shape: {model.output_shape}')

# Check that the architecture you used is compatible with the dataset (you can ignore the warnings prompted by using the GPU):
for images, labels in training_dataset.take(1):
	example_batch_images = images
	example_batch_labels = labels

try:
	model.evaluate(example_batch_images, example_batch_labels, verbose=False)
except:
	print("Your model is not compatible with the dataset you defined earlier. Check that the loss function, last layer and label_mode are compatible with one another.")
else:
	predictions = model.predict(example_batch_images, verbose=False)
	print(f"predictions have shape: {predictions.shape}")

"""# Model training"""

# Train the model (use validation data if available)
history = model.fit(
    training_dataset,
    epochs=25,
    validation_data=validation_dataset,
    callbacks=[lr_scheduler, early_stopping_cb]
)

"""# Model evaluation"""

def plot_loss_acc(history):
    '''Plots the training and validation loss and accuracy from a history object'''
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']

    epochs = range(len(acc))

    fig, ax = plt.subplots(1,2, figsize=(12, 6))
    ax[0].plot(epochs, acc, 'bo', label='Training accuracy')
    ax[0].plot(epochs, val_acc, 'b', label='Validation accuracy')
    ax[0].set_title('Training and validation accuracy')
    ax[0].set_xlabel('epochs')
    ax[0].set_ylabel('accuracy')
    ax[0].legend()

    ax[1].plot(epochs, loss, 'bo', label='Training Loss')
    ax[1].plot(epochs, val_loss, 'b', label='Validation Loss')
    ax[1].set_title('Training and validation loss')
    ax[1].set_xlabel('epochs')
    ax[1].set_ylabel('loss')
    ax[1].legend()

    plt.show()

plot_loss_acc(history)

# # calculating the testung accuracy and the testing loss
# test_loss, test_accuracy = model.evaluate(test_dataset)
# print(f'Test loss: {test_loss},\nTest accuracy: {test_accuracy}')

"""# Visualizing Intermediate Representations"""

# # List files for all categories
# categories = ['ate_by_pest', 'brown_spot_disease', 'healthy', 'leaf_blight', 'little_leaf_disease',
#               'quick_wilt', 'slow_wilt', 'sudu_pulli', 'thrips']

# for category in categories:
#     category_dir = os.path.join(TRAIN_DIR, category)
#     fnames = os.listdir(category_dir)
#     print(f"5 files in {category} subdir: {fnames[:5]}")

# import random
# import numpy as np

# # Define a new Model that will take an image as input, and will output
# # intermediate representations for all layers in the previous model
# successive_outputs = [layer.output for layer in model.layers]
# visualization_model = tf.keras.models.Model(inputs = model.inputs, outputs = successive_outputs)

# # Prepare a random input image from the training set.
# healthy_img_files = [os.path.join(healthy_dir, f) for f in train_healthy_fnames]
# leaf_blight_img_files = [os.path.join(leaf_blight_dir, f) for f in train_leaf_blight_fnames]
# yellow_mottle_virus_img_files = [os.path.join(yellow_mottle_virus_dir, f) for f in train_yellow_mottle_virus_fnames]

# img_path = random.choice(healthy_img_files + leaf_blight_img_files + yellow_mottle_virus_img_files)
# img = tf.keras.utils.load_img(img_path, target_size=(500, 500))  # this is a PIL image

# x = tf.keras.utils.img_to_array(img) # Numpy array with shape (150, 150, 3)
# x = x.reshape((1,) + x.shape) # Numpy array with shape (1, 150, 150, 3)

# # Run the image through the network, thus obtaining all
# # intermediate representations for this image.
# successive_feature_maps = visualization_model.predict(x)

# # These are the names of the layers, so you can have them as part of our plot
# layer_names = [layer.name for layer in model.layers]

# # Display the representations
# for layer_name, feature_map in zip(layer_names, successive_feature_maps):

#     if len(feature_map.shape) == 4:

#         #-------------------------------------------
#         # Just do this for the conv / maxpool layers, not the fully-connected layers
#         #-------------------------------------------
#         n_features = feature_map.shape[-1]  # number of features in the feature map
#         size = feature_map.shape[1]  # feature map shape (1, size, size, n_features)

#         # Tile the images in this matrix
#         display_grid = np.zeros((size, size * n_features))

#         #-------------------------------------------------
#         # Postprocess the feature to be visually palatable
#         #-------------------------------------------------
#         for i in range(n_features):
#             x = feature_map[0, :, :, i]
#             x -= x.mean()
#             x /= x.std ()
#             x *=  64
#             x += 128
#             x = np.clip(x, 0, 255).astype('uint8')
#             display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid

#         #-----------------
#         # Display the grid
#         #-----------------
#         scale = 20. / n_features
#         plt.figure(figsize=(scale * n_features, scale))
#         plt.title(layer_name)
#         plt.grid(False)
#         plt.imshow(display_grid, aspect='auto', cmap='viridis')

"""# Making predictions with new data"""

# import ipywidgets as widgets
# from io import BytesIO

# class_names = ['Ate by Pest', 'Brown Spot Disease', 'Healthy', 'Leaf Blight', 'Little Leaf Disease', 'Quick Wilt', 'Slow Wilt', 'Sudu Pulli', 'Thrips']

# # Create the widget and take care of the display
# uploader = widgets.FileUpload(accept="image/*", multiple=True)
# display(uploader)
# out = widgets.Output()
# display(out)

# def file_predict(filename, file, out):
#     """ A function for creating the prediction and printing the output."""
#     image = tf.keras.utils.load_img(file, target_size=(640, 640))
#     image = tf.keras.utils.img_to_array(image)
#     image = np.expand_dims(image, axis=0)

#     predictions = model.predict(image, verbose=0)[0]
#     predicted_class = class_names[np.argmax(predictions)]

#     with out:
#         print(filename + f" is a {predicted_class}")


# def on_upload_change(change):
#     """ A function for geting files from the widget and running the prediction."""
#     # Get the newly uploaded file(s)

#     for name, file_info in change.new.items(): # Accessing file information using the name as key
#         file_jpgdata = BytesIO(file_info['content']) # Accessing 'content' from file_info dictionary
#         file_predict(name, file_jpgdata, out)


# uploader.observe(on_upload_change, names='value')

"""# Saving the model

# References

- Kaggle notbook: https://www.kaggle.com/code/sunritjana/plant-disease-detection-mobilenetv2/notebook
- Keras model: https://keras.io/api/applications/mobilenet/
"""

# prompt: calculate training validation and test accucaries and loss

# Training, validation, and test metrics are already calculated and printed in the provided code.
# Here's a slightly reorganized version to make it more explicit:

# ... (Your existing code) ...

# Model evaluation
# Get training and validation accuracies
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

# Get number of epochs
epochs = range(len(acc))


# ... (Plotting code) ...

# Calculate and print test accuracy and loss
test_loss, test_accuracy = model.evaluate(test_dataset)
print(f'Test Loss: {test_loss}')
print(f'Test Accuracy: {test_accuracy}')


# Store the metrics in variables for easier access
training_accuracy = acc[-1]  # Accuracy from the last training epoch
validation_accuracy = val_acc[-1] # Accuracy from the last validation epoch
training_loss = loss[-1] # Loss from the last training epoch
validation_loss = val_loss[-1] # Loss from the last validation epoch

print("\nSummary of Metrics:")
print(f"Training Accuracy: {training_accuracy}")
print(f"Validation Accuracy: {validation_accuracy}")
print(f"Training Loss: {training_loss}")
print(f"Validation Loss: {validation_loss}")
print(f"Test Loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")

# ... (Rest of your code) ...

# Saving model to the google drive
model.save('/content/drive/MyDrive/pepper_mate_models/disease_classification_models/saved_models/mobilenet_v2_round2.keras')
model.save('/content/drive/MyDrive/pepper_mate_models/disease_classification_models/saved_models/mobilenet_v2_round2.h5')