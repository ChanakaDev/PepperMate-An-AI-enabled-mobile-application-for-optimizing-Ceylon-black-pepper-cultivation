# -*- coding: utf-8 -*-
"""6th round âœ… 1. Custom CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EmDLitFVuPX1dQV716PKmZ7xNPttmcaT

# Imports
"""

# Importing essential packages
import os
import matplotlib.pyplot as plt
import tensorflow as tf

"""# Data Loading"""

# Mounting google drive
from google.colab import drive
drive.mount('/content/drive')

# Specifying file paths for the data directories
TRAIN_DIR = '/content/drive/MyDrive/pepper_mate_models/disease_classification_models/dataset/train/'
VALIDATION_DIR = '/content/drive/MyDrive/pepper_mate_models/disease_classification_models/dataset/valid/'
TEST_DIR = '/content/drive/MyDrive/pepper_mate_models/disease_classification_models/dataset/test/'

# Specifying file paths for the each class in the training dataset
pollu_beetle_dir = os.path.join(TRAIN_DIR, 'pollu_beetle')
brown_spot_dir = os.path.join(TRAIN_DIR, 'brown_spot')
healthy_dir = os.path.join(TRAIN_DIR, 'healthy')
leaf_blight_dir = os.path.join(TRAIN_DIR, 'leaf_blight')
little_leaf_dir = os.path.join(TRAIN_DIR, 'little_leaf')
quick_wilt_dir = os.path.join(TRAIN_DIR, 'quick_wilt')
slow_wilt_dir = os.path.join(TRAIN_DIR, 'slow_wilt')
white_spot_dir = os.path.join(TRAIN_DIR, 'white_spot')
thrips_dir = os.path.join(TRAIN_DIR, 'thrips')

"""# Data visualization"""

# Loading first example of the each class
sample_pollu_beetle = tf.keras.preprocessing.image.load_img(os.path.join(pollu_beetle_dir, os.listdir(pollu_beetle_dir)[0]))
sample_brown_spot = tf.keras.preprocessing.image.load_img(os.path.join(brown_spot_dir, os.listdir(brown_spot_dir)[0]))
sample_healthy = tf.keras.preprocessing.image.load_img(os.path.join(healthy_dir, os.listdir(healthy_dir)[0]))
sample_leaf_blight = tf.keras.preprocessing.image.load_img(os.path.join(leaf_blight_dir, os.listdir(leaf_blight_dir)[0]))
sample_little_leaf_disease = tf.keras.preprocessing.image.load_img(os.path.join(little_leaf_dir, os.listdir(little_leaf_dir)[0]))
sample_quick_wilt = tf.keras.preprocessing.image.load_img(os.path.join(quick_wilt_dir, os.listdir(quick_wilt_dir)[0]))
sample_slow_wilt = tf.keras.preprocessing.image.load_img(os.path.join(slow_wilt_dir, os.listdir(slow_wilt_dir)[0]))
sample_white_spot = tf.keras.preprocessing.image.load_img(os.path.join(white_spot_dir, os.listdir(white_spot_dir)[0]))
sample_thrips = tf.keras.preprocessing.image.load_img(os.path.join(thrips_dir, os.listdir(thrips_dir)[0]))

# Create a figure and an array of subplots
fig, axes = plt.subplots(3, 3, figsize=(10, 10))

# Flatten the axes array for easier iteration
axes = axes.ravel()

# Define a list of sample images and their corresponding titles
sample_images = [
    sample_pollu_beetle, sample_brown_spot, sample_healthy,
    sample_leaf_blight, sample_little_leaf_disease, sample_quick_wilt,
    sample_slow_wilt, sample_white_spot, sample_thrips
]
titles = [
    'Pollu Beetle', 'Brown Spot', 'Healthy',
    'Leaf Blight', 'Little Leaf', 'Quick Wilt',
    'Slow Wilt', 'White Spot', 'Thrips'
]

# Iterate through the sample images and display them in the subplots
for i in range(9):  # Assuming you have 9 sample images
    axes[i].imshow(sample_images[i])
    axes[i].set_title(titles[i])
    axes[i].axis('off')

# Adjust the spacing between subplots and display the plot
plt.tight_layout()
plt.show()

# Converting an image into its numpy array representation
sample_array = tf.keras.preprocessing.image.img_to_array(sample_healthy)

print(f"Each image has shape: {sample_array.shape}")

"""# Creating training, validation and test sets"""

# Defining a function to create the training, validation and test sets
def train_val_test_datasets():
    """Creates training, validation and test datasets

    Returns:
        (tf.data.Dataset, tf.data.Dataset): training, validation and test datasets
    """

    # Create the training dataset
    # Here we have used image generators (it will do image labeling for us)
    training_dataset = tf.keras.utils.image_dataset_from_directory(
        directory=TRAIN_DIR,        # Use the training directory
        batch_size=32,              # Set batch size to 32
        image_size=(640, 640),      # Resize images to 500x500
        shuffle=True,               # Shuffle the dataset
        seed=7,                     # Set seed for reproducibility
        label_mode='categorical'    # Use categorical labels for multi-class classification
    )

    # Create the validation dataset
    validation_dataset = tf.keras.utils.image_dataset_from_directory(
        directory=VALIDATION_DIR,   # Use the validation directory
        batch_size=32,              # Set batch size to 32
        image_size=(640, 640),      # Resize images to 500x500
        shuffle=True,               # Shuffle the dataset
        seed=7,                     # Set seed for reproducibility
        label_mode='categorical'    # Use categorical labels for multi-class classification
    )

    # Create the test dataset
    test_dataset = tf.keras.utils.image_dataset_from_directory(
        directory=TEST_DIR,         # Use the test directory
        batch_size=32,              # Set batch size to 32
        image_size=(640, 640),      # Resize images to 500x500
        shuffle=True,               # Shuffle the dataset
        seed=7,                     # Set seed for reproducibility
        label_mode='categorical'    # Use categorical labels for multi-class classification
    )

    return training_dataset, validation_dataset, test_dataset

# Calling the dataset generation function
training_dataset, validation_dataset, test_dataset = train_val_test_datasets()

# Displaying a labels Tensor
for images, labels in training_dataset.take(1):
  print(labels)

# Counting number of batches in each dataset
print(f'Number of training batches: {training_dataset.cardinality()}')
print(f'Number of validation batches: {validation_dataset.cardinality()}')
print(f'Number of test batches: {test_dataset.cardinality()}')

"""# Modeling"""

from tensorflow.keras import regularizers

# Defining a function to create the model
def create_model():
    """Create the classifier model with increased complexity

    Returns:
        tf.keras.model.Sequential: CNN for multi-class classification
    """
    model = tf.keras.models.Sequential([
        # Input layer with rescaling
        tf.keras.Input(shape=(640, 640, 3)),
        tf.keras.layers.Rescaling(1./255),

        # First convolutional block with L2 regularization and dropout
        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Dropout(0.25),

        # Second convolutional block with increased filter size
        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Dropout(0.3),

        # Third convolutional block with further increased filter size
        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Dropout(0.3),

        # Fourth convolutional block with even more filters
        tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.0001)),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Dropout(0.3),

        # Flattening and dense layers with fine-tuned dropout
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),
        tf.keras.layers.Dropout(0.6),

        # Output layer for multi-class classification
        tf.keras.layers.Dense(9, activation='softmax')
    ])

    # Compile the model
    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    return model

# Calling the model creation function
model = create_model()

from tensorflow.keras import regularizers
from tensorflow.keras.callbacks import ReduceLROnPlateau
# Set up the learning rate scheduler
reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6, verbose=1)

"""# Check the model architecture"""

# Checking that the input and output shape of your model are correct
print(f'Input shape: {model.input_shape}')
print(f'Output shape: {model.output_shape}')

# Checking the model summary
model.summary()

# Check that the architecture you used is compatible with the dataset (you can ignore the warnings prompted by using the GPU):
for images, labels in training_dataset.take(1):
	example_batch_images = images
	example_batch_labels = labels

try:
	model.evaluate(example_batch_images, example_batch_labels, verbose=False)
except:
	print("Your model is not compatible with the dataset you defined earlier. Check that the loss function, last layer and label_mode are compatible with one another.")
else:
	predictions = model.predict(example_batch_images, verbose=False)
	print(f"predictions have shape: {predictions.shape}")

"""# Model training"""

# # Early stoppi g callback to stop the training process it training set reached 100% accuracy
# early_stopping = tf.keras.callbacks.EarlyStopping(
#     monitor='accuracy',
#     baseline=1.0,
#     patience=0
# )

# # Training the model with early stopping
# history = model.fit(
#     training_dataset,
#     epochs=25,
#     validation_data=validation_dataset,
#     # callbacks=[early_stopping]
# )

# Train the model with the learning rate scheduler
history = model.fit(
    training_dataset,
    epochs=25,
    validation_data=validation_dataset,
    callbacks=[reduce_lr]
)

"""# Model evaluation"""

# Get training and validation accuracies
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

# Get number of epochs
epochs = range(len(acc))

# Creating subplots for accuracy and loss
fig, ax = plt.subplots(1, 2, figsize=(10, 5))
fig.suptitle('Training and validation accuracy and loss')

# Plotting accuracy
ax[0].plot(epochs, acc, 'r', label='Training accuracy')
ax[0].plot(epochs, val_acc, 'b', label='Validation accuracy')
ax[0].set_title('Training and validation accuracy')
ax[0].legend()
ax[0].set_xlabel('Epochs')
ax[0].set_ylabel('Accuracy')

# Plotting loss
ax[1].plot(epochs, loss, 'r', label='Training loss')
ax[1].plot(epochs, val_loss, 'b', label='Validation loss')
ax[1].set_title('Training and validation loss')
ax[1].legend()
ax[1].set_xlabel('Epochs')
ax[1].set_ylabel('Loss')

plt.show()

# calculating the testung accuracy and the testing loss
test_loss, test_accuracy = model.evaluate(test_dataset)
print(f'Test loss: {test_loss},\nTest accuracy: {test_accuracy}')

"""# Visualizing Intermediate Representations"""

# List files for all categories
categories = ['pollu_beetle', 'brown_spot', 'healthy', 'leaf_blight', 'little_leaf',
              'quick_wilt', 'slow_wilt', 'white_spot', 'thrips']

for category in categories:
    category_dir = os.path.join(TRAIN_DIR, category)
    fnames = os.listdir(category_dir)
    print(f"5 files in {category} subdir: {fnames[:5]}")

import random
import numpy as np

# # Define a new Model that will take an image as input, and will output
# # intermediate representations for all layers in the previous model
# successive_outputs = [layer.output for layer in model.layers]
# visualization_model = tf.keras.models.Model(inputs = model.inputs, outputs = successive_outputs)

# # Prepare a random input image from the training set.
# healthy_img_files = [os.path.join(healthy_dir, f) for f in train_healthy_fnames]
# leaf_blight_img_files = [os.path.join(leaf_blight_dir, f) for f in train_leaf_blight_fnames]
# yellow_mottle_virus_img_files = [os.path.join(yellow_mottle_virus_dir, f) for f in train_yellow_mottle_virus_fnames]

# img_path = random.choice(healthy_img_files + leaf_blight_img_files + yellow_mottle_virus_img_files)
# img = tf.keras.utils.load_img(img_path, target_size=(500, 500))  # this is a PIL image

# x = tf.keras.utils.img_to_array(img) # Numpy array with shape (150, 150, 3)
# x = x.reshape((1,) + x.shape) # Numpy array with shape (1, 150, 150, 3)

# # Run the image through the network, thus obtaining all
# # intermediate representations for this image.
# successive_feature_maps = visualization_model.predict(x)

# # These are the names of the layers, so you can have them as part of our plot
# layer_names = [layer.name for layer in model.layers]

# # Display the representations
# for layer_name, feature_map in zip(layer_names, successive_feature_maps):

#     if len(feature_map.shape) == 4:

#         #-------------------------------------------
#         # Just do this for the conv / maxpool layers, not the fully-connected layers
#         #-------------------------------------------
#         n_features = feature_map.shape[-1]  # number of features in the feature map
#         size = feature_map.shape[1]  # feature map shape (1, size, size, n_features)

#         # Tile the images in this matrix
#         display_grid = np.zeros((size, size * n_features))

#         #-------------------------------------------------
#         # Postprocess the feature to be visually palatable
#         #-------------------------------------------------
#         for i in range(n_features):
#             x = feature_map[0, :, :, i]
#             x -= x.mean()
#             x /= x.std ()
#             x *=  64
#             x += 128
#             x = np.clip(x, 0, 255).astype('uint8')
#             display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid

#         #-----------------
#         # Display the grid
#         #-----------------
#         scale = 20. / n_features
#         plt.figure(figsize=(scale * n_features, scale))
#         plt.title(layer_name)
#         plt.grid(False)
#         plt.imshow(display_grid, aspect='auto', cmap='viridis')

"""# Making predictions with unseen data"""

import ipywidgets as widgets
from io import BytesIO

class_names = ['Pollu Beetle', 'Brown Spot', 'Healthy', 'Leaf Blight', 'Little Leaf', 'Quick Wilt', 'Slow Wilt', 'White Spot', 'Thrips']

# Create the widget and take care of the display
uploader = widgets.FileUpload(accept="image/*", multiple=True)
display(uploader)
out = widgets.Output()
display(out)

def file_predict(filename, file, out):
    """ A function for creating the prediction and printing the output."""
    image = tf.keras.utils.load_img(file, target_size=(640, 640))
    image = tf.keras.utils.img_to_array(image)
    image = np.expand_dims(image, axis=0)

    predictions = model.predict(image, verbose=0)[0]
    predicted_class = class_names[np.argmax(predictions)]

    with out:
        print(filename + f" is a {predicted_class}")


def on_upload_change(change):
    """ A function for geting files from the widget and running the prediction."""
    # Get the newly uploaded file(s)

    for name, file_info in change.new.items(): # Accessing file information using the name as key
        file_jpgdata = BytesIO(file_info['content']) # Accessing 'content' from file_info dictionary
        file_predict(name, file_jpgdata, out)


uploader.observe(on_upload_change, names='value')

"""# Saving the model"""

# Saving model to the google drive
model.save('/content/drive/MyDrive/pepper_mate_models/disease_classification_models/saved_models/custom_cnn_6th_round.keras')
model.save('/content/drive/MyDrive/pepper_mate_models/disease_classification_models/saved_models/custom_cnn_6th_round.h5')

# prompt: calculate training validation and test accucaries and loss

# Training, validation, and test metrics are already calculated and printed in the provided code.
# Here's a slightly reorganized version to make it more explicit:

# ... (Your existing code) ...

# Model evaluation
# Get training and validation accuracies
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

# Get number of epochs
epochs = range(len(acc))


# ... (Plotting code) ...

# Calculate and print test accuracy and loss
test_loss, test_accuracy = model.evaluate(test_dataset)
print(f'Test Loss: {test_loss}')
print(f'Test Accuracy: {test_accuracy}')


# Store the metrics in variables for easier access
training_accuracy = acc[-1]  # Accuracy from the last training epoch
validation_accuracy = val_acc[-1] # Accuracy from the last validation epoch
training_loss = loss[-1] # Loss from the last training epoch
validation_loss = val_loss[-1] # Loss from the last validation epoch

print("\nSummary of Metrics:")
print(f"Training Accuracy: {training_accuracy}")
print(f"Validation Accuracy: {validation_accuracy}")
print(f"Training Loss: {training_loss}")
print(f"Validation Loss: {validation_loss}")
print(f"Test Loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")

# ... (Rest of your code) ...