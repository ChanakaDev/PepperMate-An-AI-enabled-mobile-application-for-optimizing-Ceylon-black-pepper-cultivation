# -*- coding: utf-8 -*-
"""✅ 4. rag_bot_with_claude.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10QsvEFMRtN2aSRyRAFSC3gJD3B4Wl7G_
"""

# Install necessary packages
!pip install langchain -qU
!pip install langchain-anthropic -qU
!pip install langchain-chroma -qU
!pip install langchain_community -qU
!pip install pypdf -qU
!pip install sentence-transformers -qU

import os
import tempfile
from langchain_anthropic import ChatAnthropic
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import create_retrieval_chain, create_history_aware_retriever
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

# Initialize Claude
os.environ['ANTHROPIC_API_KEY'] = 'your_anthropic_api_key'
llm = ChatAnthropic(
    model="claude-3-sonnet-20240229",
    temperature=0
)

# Initialize Embedding Model with SentenceTransformer instead of BERT
embedding_model = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-mpnet-base-v2",
    model_kwargs={'device': 'cpu'}
)

# Create a temporary directory for Chroma
persist_directory = tempfile.mkdtemp()

# Load PDF Document
loader = PyPDFLoader("pepper_final.pdf")
docs = loader.load()

# Split Documents into Chunks
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=400,
    chunk_overlap=50
)
splits = text_splitter.split_documents(docs)

# Create Vector Store and Retriever with temporary directory
vectorstore = Chroma.from_documents(
    documents=splits,
    embedding=embedding_model,
    persist_directory=persist_directory
)
retriever = vectorstore.as_retriever()

# Define Prompt Template
system_prompt = """You are an intelligent chatbot. Use the following context to answer the question.
If you don't know the answer, just say that you don't know.

{context}"""

prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    ("human", "{input}"),
])

# Create Basic RAG Chain
qa_chain = create_stuff_documents_chain(llm, prompt)
rag_chain = create_retrieval_chain(retriever, qa_chain)

# Add Chat History Awareness
contextualize_system_prompt = """Using chat history and the latest user question,
reformulate the question to be a standalone question if needed."""

contextualize_prompt = ChatPromptTemplate.from_messages([
    ("system", contextualize_system_prompt),
    MessagesPlaceholder("chat_history"),
    ("human", "{input}"),
])

# Create History-Aware Retriever
history_aware_retriever = create_history_aware_retriever(
    llm,
    retriever,
    contextualize_prompt
)

# Update Prompt with Chat History
prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    MessagesPlaceholder("chat_history"),
    ("human", "{input}"),
])

# Create History-Aware RAG Chain
qa_chain = create_stuff_documents_chain(llm, prompt)
rag_chain = create_retrieval_chain(history_aware_retriever, qa_chain)

# Manage Chat Session History
store = {}

def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

# Create Conversational RAG Chain
conversational_rag_chain = RunnableWithMessageHistory(
    rag_chain,
    get_session_history,
    input_messages_key="input",
    history_messages_key="chat_history",
    output_messages_key="answer",
)

# Example Usage
try:
    response = conversational_rag_chain.invoke(
        {"input": "ක්ෂණික මැලවීම රෝගය පාලනය කරගන්නෙ කොහොමද?"},
        config={"configurable": {"session_id": "101"}},
    )
    print(response["answer"])
finally:
    # Clean up the temporary directory
    vectorstore.delete_collection()
    import shutil
    shutil.rmtree(persist_directory)

"""ක්ෂණික මැලවීම ෙරෝගය පාලනය කිරීම සඳහා පහත සඳහන් ක්රියාමාර්ග අනුගමනය කළ හැකිය:

1. ක්ෙෂ්ත්රෙය් ජලය හොඳින් බැසයාමට සැලසුම් කිරීම සහ නිෙදර්ශිත ෙලස ෙසවන පාලනය කිරීම.
2. වැසි කාලවලදී වැල් වටා ඇති වසුන් ඉවත් කිරීම.
3. ෙපොළව මට්ටෙමන් අඩි 1 1/2 ක් පමණ උසට ඇති හරස් අතු ඉවත් කිරීම.
4. ආසාදනය වූ අතු හා මුල් ෙකොටස් ඉවත් කර පුළුස්සා දැමීම.
5. ෙරෝගය දුටු මුල් අවස්ථාෙව්ම ආසාදිත මුල් ෙහොඳින් පිරිසිදු කර මූණෙතහි ෙබෝෙඩෝ පැප්පය ආෙල්ප කිරීම ෙහෝ 1% ෙබෝෙඩෝ මිශ්රණෙයන් ෙතමන්න.

එෙමන්ම, ෙරෝගය වැඩිපුර පැතිරෙයන්ෙන් තද වැසි කාලවලට පසුව එළෙඹන වියළි කාලයන්හිදී බව සඳහන් වී ඇති බැවින්, එවැනි කාලවලදී විෙශේෂ අවධානයක් ෙයොමු කළ යුතුය.
"""